{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# IMOS Ocean Radar Data Query\n",
    "\n",
    "**Acknowlegement** &mdash; This  is based on the Ipython material from <a href:'https://github.com/DamienIrving/CV/blob/master/CV.md'>Damien Irving</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Installing modules\n",
    "\n",
    "A module is a Python object with arbitrarily named attributes that you can bind and reference. A module is a fit-2-purpose piece of code which defines \n",
    "\n",
    "+ functions, \n",
    "+ classes, \n",
    "+ variables, \n",
    "+ a runnable code.\n",
    "\n",
    "Installing a module is usually done using Python Package Installer: <code>pip</code>. \n",
    "\n",
    "All the modules that you will require for this UoS have already been installed on the server, so you will have nothing to install but you will still have to load the modules on the IPython environment.\n",
    "\n",
    "We will need **netCDF** libray (<a ref='http://www.unidata.ucar.edu/netcdf/'>Network Common Data Form</a>) is a set of software libraries and self-describing, machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data. The project homepage is hosted by the **Unidata** program at the University Corporation for Atmospheric Research (**UCAR**).\n",
    "\n",
    "Loading a module is straight forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from netCDF4 import Dataset\n",
    "from netCDF4 import num2date\n",
    "from IPython.core.display import HTML\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Data server = Data access ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('7yTpv70gkGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## In a nutshell...\n",
    "\n",
    "* Data access is provided via **HTTP** and **OPeNDAP** by **THREDDS** Data Server and **FTP**. \n",
    "* Most data providers are using interactive visualization of data sets with zoomable maps. \n",
    "\n",
    "To understand data server you need to be familiar with these key transfer protocols:\n",
    "\n",
    "#### HTTP: Hypertext Transfer Protocol\n",
    "#### OPenDAP: Open-source Project for a Network Data Access Protocol\n",
    "#### THREDDS: Thematic Real-Time Environmental Distributed Data Services\n",
    "#### FTP: File Transfer Protocol\n",
    "#### LAS: Live Access Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Get the data from IMOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turquoise bay\n",
    "acorn_URL = 'http://thredds.aodn.org.au/thredds/dodsC/IMOS/eMII/demos/ACORN/monthly_gridded_1h-avg-current-map_non-QC/TURQ/2012/IMOS_ACORN_V_20121001T000000Z_TURQ_FV00_monthly-1-hour-avg_END-20121029T180000Z_C-20121030T160000Z.nc.gz'\n",
    "# Other ACORN data as an example:\n",
    "# South Australia Gulf\n",
    "#acorn_URL = 'http://thredds.aodn.org.au/thredds/dodsC/IMOS/ACORN/monthly_gridded_1h-avg-current-map_non-QC/SAG/2015/IMOS_ACORN_V_20150101T003000Z_SAG_FV00_monthly-1-hour-avg_END-20150131T233000Z_C-20150201T235953Z.nc'\n",
    "# Bonney Coast\n",
    "#acorn_URL = 'http://thredds.aodn.org.au/thredds/dodsC/IMOS/ACORN/monthly_gridded_1h-avg-current-map_non-QC/BONC/2015/IMOS_ACORN_V_20150101T000000Z_BONC_FV00_monthly-1-hour-avg_END-20150131T190000Z_C-20150202T000206Z.nc'\n",
    "\n",
    "acorn_DATA = Dataset(acorn_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The first thing to notice is the distinctive **Data Reference Syntax** (DRS) associated with the file. The staff at IMOS have archived the data according to the following directory structure:\n",
    "\n",
    "**http://thredds.aodn.org.au/thredds/dodsC/project/organisation/collection/facility/data-type/site-code/year/**\n",
    "\n",
    "From this we can deduce, without even inspecting the contents of the file, that we have data from the IMOS project that is run by the eMarine Information Infrastructure (eMII). It was collected in 2012 at the Turquoise Coast, Western Australia (TURQ) site of the Australian Coastal Ocean Radar Network (ACORN), which is a network of high frequency radars that measure the ocean surface current (see this <a href='http://researchdata.ands.org.au/imos-acorn-turquoise-australia-australia/442676'>page</a> on the Research Data Australia website for a nice overview of the dataset).\n",
    "\n",
    "<br/>\n",
    "<small>While it's unlikely that your research will ever involve cataloging data from such a large observational network, it's still a very good idea to develop your own personal DRS for the data you do have. This often involves investing some time at the beginning of a project to think carefully about the design of your directory and file name structures, as these can be very hard to change later on (a good example is the <a ref='http://cmip-pcmdi.llnl.gov/cmip5/docs/cmip5_data_reference_syntax.pdf'>DRS</a> used by the Climate Model Intercomparison Project). The combination of bash shell wildcards and a well planned DRS is one of the easiest ways to make your research more efficient and reliable.\n",
    "</small>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The data type has a sub-DRS of its own, which tells us that the data represents the 1-hourly average surface current for a single month (October 2012), and that it is archived on a regularly spaced spatial grid and has not been quality controlled. The file is located in the \"demos\" directory, as it has been generated for the purpose of providing an example for users in the very helpful <a ref='http://portal.aodn.org.au/aodn/'>Australian Ocean Data Network</a> (AODN) <a href='https://github.com/aodn/imos-user-code-library'> user code library</a>.\n",
    "\n",
    "Just in case the file gets separated from this informative directory stucture, much of the information is repeated in the file name itself, along with some more detailed information about the start and end time of the data, and the last time the file was modified.\n",
    "\n",
    "**project_facility_V_time-start_site-code_FV00_data-type_time-end_modified.nc.gz**\n",
    "\n",
    "In the first instance this level of detail seems like a bit of overkill, but consider the scope of the IMOS data archive. It is the final resting place for data collected by the entire national array of oceanographic observing equipment in Australia, which monitors the open oceans and coastal marine environment covering physical, chemical and biological variables. Since the data are so well labelled, locating all monthly timescale ACORN data from the Turquoise Coast and Rottnest Shelf sites (which represents hundreds of files) would be as simple as typing the following at the command line:\n",
    "\n",
    "**ls */ACORN/monthly_*/{TURQ,ROT}/\\*/\\*.nc**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Check the loaded ACORN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print acorn_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Query the dataset\n",
    "\n",
    "The great thing about netCDF files is that they contain <a href=http://en.wikipedia.org/wiki/Metadata>metadata</a> - that is, data about the data. There are global attributes that give information about the file as a whole, while each variable also has its own attributes.\n",
    "\n",
    "The file contains the following variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print acorn_DATA.variables.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The 'u' means each variable name is represented by a Unicode string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'These are the attributes of the time axis:'\n",
    "print acorn_DATA.variables['TIME']\n",
    "print 'These are some of the time values:'\n",
    "print acorn_DATA.variables['TIME'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The raw time values are fairly meaningless, but we can use the time attributes to convert them to a more meaningful format..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "units = acorn_DATA.variables['TIME'].units\n",
    "calendar = acorn_DATA.variables['TIME'].calendar\n",
    "\n",
    "times = num2date(acorn_DATA.variables['TIME'][:], units=units, calendar=calendar)\n",
    "print times[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<blockquote>\n",
    "    <h2>Climate and Forecast (CF) metadata convention</h2>\n",
    "    <p>When performing simple data analysis tasks on netCDF files, command line tools like the Climate Data Operators (<a href=\"https://code.zmaw.de/projects/cdo\">CDO</a>) are often a better alternative to writing your own functions in Python. However, let's put ourselves in the shoes of the developers of CDO for a minute. In order to calculate the time mean of a dataset for a given start and end date (for example), CDO must first identify the units of the time axis. This isn't as easy as you'd think, since the creator of the netCDF file could easily have called the units attribute measure, or scale, or something else completely unpredictable. They could also have defined the units as weeks since 1-01-01 00:00:00 or milliseconds after 1979-12-31. Obviously what is needed is a standard method for defining netCDF attributes, and that’s where the <a href='http://cf-pcmdi.llnl.gov/'>Climate and Forecast (CF) metadata convention</a> comes in.</p>\n",
    "    <p>The CF metadata standard was first defined back in the early 2000s and has now been adopted by all the major institutions and projects in the weather/climate sciences. There's a nice <a href='http://drclimate.wordpress.com/2014/06/09/are-you-cf-compliant/'>blog post</a> on the topic if you'd like more information, but for the most part you just need to be aware that if a tool like CDO isn't working, it might be because your netCDF file isn't CF compliant.</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Calculating the current speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For the sake of example, let's say that our data file contained the zonal (east/west; 'UCUR') and meridional (north/south; 'VCUR') surface current components, but not the total current speed. To calculate it, we first need to assign a variable to the zonal and meridional current data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uData = acorn_DATA.variables['UCUR'][:,:,:]\n",
    "vData = acorn_DATA.variables['VCUR'][:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both <i>uData</i> and <i>vData</i> are a special type of numpy array known as a masked array, whereby some of the points in the time/latitude/longitude grid have missing (or masked) values. Just as with a normal numpy array, we can check the shape of our data (in fact, masked arrays can do everything normal numpy arrays can do and more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(uData)\n",
    "print uData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, 493 time steps, 55 latitudes and 57 longitudes. We can now go ahead and calculate the current speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spData = (uData**2 + vData**2)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Viewing Turquoise Bay uploaded dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a good idea to regularly view your data throughout the code development process, just to ensure nothing crazy has happened along the way. Below is a code except from this <a href='https://github.com/aodn/imos-user-code-library/blob/master/Python/demos/acorn.py'>example</a> in the AODN user code library, which simply plots one of the 493 timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
     "LAT = acorn_DATA.variables['LATITUDE']\n",
     "LON = acorn_DATA.variables['LONGITUDE']\n",
     "TIME = acorn_DATA.variables['TIME']\n",
     "\n",
     "# Only one time value is being plotted. modify timeIndex if desired (value between 0 and length(timeData)-1 )\n",
     "timeIndex = 4\n",
     "speedData = spData[timeIndex,:,:]\n",
     "latData = LAT[:]\n",
     "lonData = LON[:]\n",
     "\n",
     "# sea water U and V components\n",
     "uData = acorn_DATA.variables['UCUR'][timeIndex,:,:]\n",
     "vData = acorn_DATA.variables['VCUR'][timeIndex,:,:]\n",
     "units = acorn_DATA.variables['UCUR'].units\n",
     "\n",
     "figure1 = plt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
     "plt.pcolor(lonData , latData, speedData)\n",
     "cbar = plt.colorbar()\n",
     "cbar.ax.set_ylabel('Current speed in ' + units)\n",
     "\n",
     "plt.title(acorn_DATA.title + '\\n' + num2date(TIME[timeIndex], TIME.units, TIME.calendar).strftime('%d/%m/%Y'))\n",
     "plt.xlabel(LON.long_name + ' in ' + LON.units)\n",
     "plt.ylabel(LAT.long_name + ' in ' + LAT.units)\n",
     "\n",
     "#plot velocity field\n",
     "Q = plt.quiver(lonData[:], latData[:], uData, vData, units='width')\n",
     "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
